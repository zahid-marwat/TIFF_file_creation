{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 140 unique views to Data/outputTiff2.tiff.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re\n",
    "\n",
    "def parse_srt(srt_file):\n",
    "    lat_long_data = []\n",
    "    with open(srt_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    lat_long_pattern = re.compile(r'\\[latitude: ([\\d.-]+)\\] \\[longitude: ([\\d.-]+)\\]')\n",
    "    \n",
    "    for line in lines:\n",
    "        match = lat_long_pattern.search(line)\n",
    "        if match:\n",
    "            lat = float(match.group(1))\n",
    "            long = float(match.group(2))\n",
    "            lat_long_data.append((lat, long))\n",
    "    \n",
    "    return lat_long_data\n",
    "def parse_excel(excel_file):\n",
    "    df = pd.read_excel(excel_file)\n",
    "    # total_length_road = df['TOTAL LENGTH OF ROAD IN ONE IMAGE'].values[0]\n",
    "    # total_length_segment = df['TOTAL LENGTH OF SEGMENT'].values[0]\n",
    "    total_length_road = 4.42\n",
    "    total_length_segment = 610\n",
    "    return total_length_road, total_length_segment\n",
    "    \n",
    "def video_to_unique_views(video_path, srt_file, excel_file, output_filename):\n",
    "    total_length_road, total_length_segment = parse_excel(excel_file)\n",
    "    total_views = int(total_length_segment / total_length_road)\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frames = []\n",
    "    lat_long_data = parse_srt(srt_file)\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = total_frames // total_views if total_views > 0 else 1\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if len(lat_long_data) > frame_count // frame_interval:\n",
    "                lat, long = lat_long_data[frame_count // frame_interval]\n",
    "                cv2.putText(frame_rgb, f\"Lat: {lat:.6f}, Long: {long:.6f}\", \n",
    "                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "            frames.append(frame_rgb)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if frames:\n",
    "        # Stack frames vertically\n",
    "        stacked_image = np.vstack(frames)\n",
    "\n",
    "        # Convert the stacked NumPy array back to a PIL Image\n",
    "        pil_image = Image.fromarray(stacked_image)\n",
    "\n",
    "        # Save as a single TIFF file\n",
    "        pil_image.save(output_filename, compression='tiff_lzw')\n",
    "\n",
    "    print(f\"Saved {len(frames)} unique views to {output_filename}.\")\n",
    "\n",
    "video_to_unique_views(\n",
    "    \"Data/DJI_0008.MP4\", \n",
    "    \"Data/DJI_0008.SRT\", \n",
    "    \"Data/Survey Form Segment 7.xlsx\", \n",
    "    \"Data/outputTiff2.tiff\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
